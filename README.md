# DL-Based-Vulnerability-Detection
Deep Learning Based Vulnerability Detection

Do sự thiên vị trong dataset dẫn đến khi test trong thực tế thì accuracy lại giảm mặc dù khi train accuracy lên đến 95%, cho dù có train trên tập vulnerability trong thực tế thì accuracy cũng giảm khoảng 11%, vấn đề cũng là do thiên vị trong dataset

**SMOTE (Synthetic Minority Over-sampling Technique) là 1 phương pháp trong việc tăng cường dữ liệu cho lớp thiểu số trong bài toán phân loại**

=> Để giải quyết điều này, thì ta tiến hành lấy mẫu lại để cân bằng tỷ lệ giữa các label, SMOTE sẽ tiến hành xóa ngãu nhiên 1 số ví dụ trong khi siêu lấy mẫu lớp thiểu số (bằng cách tạo ra các ví dụ tổng hợp) cho đến khi tất cả các lớp có cùng tần số

    * SMOTE sẽ chọn một mẫu ngẫu nhiên chứa vulnerability và tìm k hàng xóm vulnerabilities gần nhất sau đó nó xây dựng 1 lớp tổng hợp cho một lớp thiểu số trong bài toán phân loại, một vấn đề thường gặp là mô hình có thể không học được đủ thông tin từ lớp này, do sự mất cân bằng dữ liệu. 
    
    * SMOTE được sử dụng để giả lập thêm các mẫu dữ liệu trong lớp thiểu số để cải thiện khả năng phân loại của mô hình. Quá trình SMOTE có bước quan trọng là tạo ra các mẫu tổ hợp mới. Đối với mỗi mẫu dữ liệu trong lớp thiểu số đã chọn, SMOTE chọn ngẫu nhiên một láng giềng gần nhất, sau đó tạo ra một mẫu mới bằng cách nội suy (interpolate) giữa mẫu này và láng giềng.
    
    * Nội suy ở đây có thể được hiểu như việc tạo ra một mẫu dữ liệu mới nằm giữa hai mẫu đã có. Đối với mỗi đặc trưng của mẫu, giá trị của đặc trưng mới được tính toán bằng cách lấy trung bình hoặc trọng số trung bình của đặc trưng tương ứng từ hai mẫu đã có. 
    
        * Ví dụ, nếu có hai mẫu A và B, và chúng có các giá trị đặc trưng lần lượt là A = [a1, a2, a3] và B= [b1 , b2, b3], thì mẫu mới sẽ có giá trị đặc trưng là C=[(a1 ​+ b1 )/2, (a2 + b2)/2, (a3 ​+ b3)/2]. 
        
        * Quá trình này giúp tạo ra các mẫu dữ liệu mới có đặc tính giống với lớp thiểu số, nhưng có độ biến động và đa dạng để cung cấp thêm thông tin cho mô hình phân loại.

==> Quá trình này lặp đi lặp lại cho đến khi dataset được cân bằng thì ngưng

Chia dataset tương ứng train, test, validation là 70%, 20% và 10%

**Kịch Bản-A (Sử Dụng Các Mô Hình Đã Huấn Luyện Trước)**

    * Mục Tiêu:

        * Sử dụng các mô hình đã được huấn luyện trước với dữ liệu đơn giản (được mô phỏng lỗ hổng) để dự đoán lỗ hổng trong môi trường thực tế.

    * Quy Trình Thực Hiện:

        * Huấn luyện các mô hình cơ bản với dữ liệu đơn giản theo cách mà các tác giả của bài báo đã mô tả.

        * Sử dụng các mô hình đã được huấn luyện trước để dự đoán lỗ hổng trong dữ liệu thực tế, chẳng hạn như trên FFMPeg+Qemu và REVEAL dataset.

    * Quan Sát và Kết Quả:

Kết quả thể hiện trong Bảng 3b của bài báo.

Hiệu suất của các mô hình giảm đáng kể khi áp dụng cho dự đoán lỗ hổng thực tế. Ví dụ, F1-score của VulDeePecker giảm từ 85.4% (trong kết quả cơ bản) xuống chỉ còn 12.18% trên REVEAL dataset.

**Kịch Bản-B (Huấn Luyện Lại Các Mô Hình với Dữ Liệu Thực Tế)**

    * Mục Tiêu:

        * Huấn luyện lại các mô hình với dữ liệu thực tế và đánh giá hiệu suất của chúng khi áp dụng cho dự đoán lỗ hổng thực tế.
    * Quy Trình Thực Hiện:

        * Sử dụng một phần của FFMPeg+Qemu và REVEAL dataset để huấn luyện lại mỗi mô hình.
        * Sử dụng các mô hình đã được huấn luyện lại để dự đoán lỗ hổng trên phần dữ liệu còn lại của FFMPeg+Qemu và REVEAL dataset.
        * Lặp lại quá trình trên 30 lần với các phần khác nhau của dữ liệu để đánh giá độ ổn định và độ chính xác của mô hình.

    * Quan Sát và Kết Quả:

Kết quả được thể hiện trong Bảng 3c của bài báo.

Hiệu suất của các mô hình vẫn giảm đáng kể so với kết quả cơ bản khi áp dụng cho dự đoán lỗ hổng thực tế. Ví dụ, F1-score trung bình giảm khoảng 54%.

**Tổng Kết và Nhận Xét:**

    * Cả hai kịch bản đều cho thấy sự giảm đáng kể trong hiệu suất của các mô hình khi chúng được áp dụng vào dự đoán lỗ hổng thực tế.

    * Mức giảm hiệu suất là lớn, và bài báo đề xuất rằng các phương pháp hiện tại cần phải được cải thiện để có thể tổng quát hóa tốt hơn trên dữ liệu thực tế.

    * Điều này có thể đặt ra thách thức trong việc ứng dụng các mô hình dự đoán lỗ hổng bảo mật sử dụng Deep Learning trong môi trường thực tế.

![Alt text](image.png)

(1) Khi sử dụng các mô hình được đào tạo trước (tức là Kịch bản-A trong RQ1) để dự đoán các lỗ hổng trong thế giới thực, tỷ lệ giữa các ví dụ dễ bị tổn thương và trung tính khác nhau đáng kể trong tập dữ liệu huấn luyện và thử nghiệm. 

=> Điều này giải thích tại sao các mô hình được huấn luyện trước lại hoạt động kém (như trong Bảng 3b). 

(2) Khi các mô hình được đào tạo lại, chúng có xu hướng thiên về lớp có nhiều mẫu nhất (tức là lớp đa số )

=> Điều này dẫn đến giá trị thu hồi kém (tức là chúng bỏ sót rất nhiều lỗ hổng thực sự) và do đó, cả điểm F1 (như trong Bảng 3c)